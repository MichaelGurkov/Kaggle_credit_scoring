
```{r libraries}

library(tidymodels)

library(tidyverse)

library(tictoc)

library(doParallel)

library(vip)


```

```{r load_data}

data("train_set")

data("test_set")

data("names_table")

train_set = train_set %>% 
  rename_at(names_table$full_name, ~names_table$feature_name)

test_set = test_set %>% 
  rename_at(names_table$full_name, ~names_table$feature_name)


```

```{r split_data}

indices = list(analysis = seq(nrow(train_set)),
               assessment = nrow(train_set) + seq(nrow(test_set)))

comb_data = train_set %>% 
  bind_rows(test_set)

data_split = make_splits(ind = indices, data = comb_data)

rm(indices, test_set, comb_data)

train_set = training(data_split)

train_set = train_set %>% 
  slice_sample(n = 50000)

```

```{r define_preprocess_recipes}

preprocess_recipe = recipe(formula = target ~ ., data = train_set) %>%
  step_mutate(target = factor(target, levels = c(1, 0))) %>%
  step_impute_median("dependents")  %>%
  step_impute_median("income") %>% 
  step_filter(income >= 1000) %>%
  step_mutate_at(c("income", "debt_ratio", "ruul"),
                 fn = ~ DescTools::Winsorize(., probs = c(0, 0.95),
                                             na.rm = TRUE)) %>% 
  step_mutate(debt_log = (log(debt_ratio * income + 1))) %>% 
  step_center(contains("due")) %>% 
  identity()


```

```{r define_models}

rf_mod = rand_forest(mtry = tune(),trees = 1000) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")



```

```{r set_cv_params}

cv_resamples = vfold_cv(v = 5, data = train_set)


```

```{r tune_parameters}


rf_wf = workflow() %>% 
  add_recipe(preprocess_recipe) %>% 
  add_model(rf_mod)

tic()

cl = makePSOCKcluster(3)

registerDoParallel()

rf_res = rf_wf %>%
  tune_grid(resamples = cv_resamples,grid = 10)

stopCluster(cl)

toc()

```

```{r fit_model, eval=FALSE}

rf_fit = workflow() %>%
  add_recipe(preprocess_recipe) %>%
  add_model(rand_forest(mode = "classification", mtry = 1, trees = 1000) %>%
              set_engine("ranger",importance = "impurity")) %>%
  fit(train_set)

```

```{r plot_feature_importance, eval=FALSE}

rf_fit %>% 
  extract_fit_parsnip() %>% 
  vip() + 
  ggtitle("Feature importance")

```

```{r plot_tune_metrics, eval=FALSE}

metrics = rf_res %>% 
  collect_metrics() %>% 
  filter(.metric == "roc_auc")

ggplot() +
  geom_point(data = metrics, aes(x = as_factor(mtry), y = mean)) +
  geom_errorbar(data = metrics, aes(
    x = as_factor(mtry),
    ymin = mean - std_err,
    ymax = mean + std_err
  ))

```

```{r forecast, eval=FALSE}

forecast = rf_wf %>% 
  finalize_workflow(rf_res %>%
                select_best("roc_auc")) %>% 
  last_fit(data_split)


forecast_df = forecast %>% 
  collect_predictions()


forecast_df %>%
  mutate(Id = row_number()) %>%
  select(Id, Probability = .pred_1) %>%
  write_csv("C:\\Users\\Home\\Desktop\\rf.csv")


```

